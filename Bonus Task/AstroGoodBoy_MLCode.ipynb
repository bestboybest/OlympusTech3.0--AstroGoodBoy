{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57ac9303",
   "metadata": {},
   "source": [
    "# Bonus Task\n",
    "\n",
    "We need to develop a machine learning model trained on the processsed dataset to detect which passengers were transported by the anomaly. We will predict on provided test.csv.\n",
    "\n",
    "We have already cleaned_dataset.csv which is a cleaned dataset that we can use as the training dataset. \n",
    "\n",
    "We also need to clean test.csv, which we will clean in the same way we cleaned train taking values from train ONLY. (so we only clean test and don't like influence our outcomes based on 'knowing' the test dataset)\n",
    "\n",
    "We will do this by creating a 'cleaning function', then we will reclean our original unclean dataset using that function making sure that we get a similar result as our cleaned_dataset, and then apply that cleaning function on test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0e2f17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries here\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42269e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import our required datasets\n",
    "\n",
    "cleaned = pd.read_csv('../Task2/cleaned_dataset.csv')\n",
    "train = pd.read_csv('../Data/train.csv')\n",
    "test = pd.read_csv('../Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6fa6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create our cleaning function (I will be looking in #AstroGoodBoy_notebook_cleaning for reference and getting the same code in)\n",
    "np.random.seed(69)\n",
    "\n",
    "def clean(data):\n",
    "    cleanData = data.copy()\n",
    "\n",
    "    #PassengerId + Name column stuff\n",
    "    cleanData['GroupId'] = data['PassengerId'].str[:4]\n",
    "    cleanData['GroupSize'] = data.groupby(data['PassengerId'].str[:4]).transform('size')\n",
    "\n",
    "    #HomePlanet and Destination stuff\n",
    "    cleanData['HomePlanet'] = cleanData.groupby(cleanData['GroupId'])['HomePlanet'].transform('first')\n",
    "    cleanData['HomePlanet'] = cleanData['HomePlanet'].fillna('Earth')\n",
    "    cleanData['Destination'] = cleanData['Destination'].fillna('TRAPPIST-1e')\n",
    "\n",
    "    #Cabin stuff\n",
    "    cleanData[['Cabin P1', 'Cabin P2', 'Cabin P3']] = cleanData['Cabin'].str.split(\"/\", expand = True)\n",
    "    cleanData['Cabin P2'] = cleanData['Cabin P2'].astype('Int64')\n",
    "    cleanData['Cabin P1'] = cleanData['Cabin P1'].replace('T', 'F')\n",
    "    cleanData['Cabin P1'] = cleanData['Cabin P1'].fillna('F')\n",
    "\n",
    "    #We needed a randomfill function to do a bunch of our work\n",
    "    #We need to somehow make sure we get random values from train.csv and put in test.csv (we not allowed to access test.csv values)\n",
    "    #Instead to solve this issue, we will change our randomFill code to always take values from our already CLEANED dataset!\n",
    "    def randomFill(column):\n",
    "      SGMRW = column.copy()\n",
    "      indices = SGMRW[SGMRW.isna()].index\n",
    "      randomVals = np.random.choice(cleaned[column.name], size = SGMRW.isna().sum(), replace = True)\n",
    "      SGMRW.loc[indices] = randomVals\n",
    "      return SGMRW\n",
    "\n",
    "    #More cabin stuff\n",
    "    cleanData['Cabin P2'] = cleanData.groupby(cleanData['Cabin P1'])['Cabin P2'].transform(lambda x: randomFill(x))\n",
    "    cleanData['Cabin P3'] = cleanData.groupby(cleanData['GroupId'])['Cabin P3'].transform('first')\n",
    "    cleanData['Cabin P3'] = randomFill(cleanData['Cabin P3'])\n",
    "    cleanData['Cabin'] = cleanData['Cabin P1'].astype(str) + '/' + cleanData['Cabin P2'].astype(str) + '/' + cleanData['Cabin P3'].astype(str)\n",
    "\n",
    "    #Cryosleep, VIP and some spendings stuff\n",
    "    cleanData['VIP'] = (cleanData['VIP']).astype(bool)\n",
    "    cleanData['VIP'] = cleanData['VIP'].fillna(False)\n",
    "    #lmao this part looking very inefficient now but whatever \n",
    "    tempData = cleanData.copy()\n",
    "    tempData['RoomService'] = tempData['RoomService'].fillna(0.0)\n",
    "    tempData['FoodCourt'] = tempData['FoodCourt'].fillna(0.0)\n",
    "    tempData['ShoppingMall'] = tempData['ShoppingMall'].fillna(0.0)\n",
    "    tempData['Spa'] = tempData['Spa'].fillna(0.0)\n",
    "    tempData['VRDeck'] = tempData['VRDeck'].fillna(0.0)\n",
    "    indices = cleanData[(cleanData['CryoSleep'].isna() == True) & ((cleanData['RoomService'] + cleanData['FoodCourt'] + cleanData['ShoppingMall'] + cleanData['Spa'] + cleanData['VRDeck']) != 0) & ((tempData['RoomService'] + tempData['FoodCourt'] + tempData['ShoppingMall'] + tempData['Spa'] + tempData['VRDeck']) == 0)].index\n",
    "    cleanData.loc[indices, 'CryoSleep'] = True\n",
    "    cleanData.loc[indices, 'RoomService':'VRDeck'] = 0.0\n",
    "    indices = cleanData[(cleanData['CryoSleep'].isna() == True) & ((cleanData['RoomService'] + cleanData['FoodCourt'] + cleanData['ShoppingMall'] + cleanData['Spa'] + cleanData['VRDeck']) == 0)].index\n",
    "    cleanData.loc[indices, 'CryoSleep'] = True\n",
    "    cleanData['CryoSleep'] = (cleanData['CryoSleep']).astype(bool)\n",
    "    cleanData['CryoSleep'] = cleanData['CryoSleep'].fillna(False)\n",
    "    cleanData.loc[cleanData['CryoSleep'] == True, 'RoomService':'VRDeck'] = 0\n",
    "\n",
    "    #Age and spendings stuff\n",
    "    spendings = cleanData[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].fillna(0).sum(axis = 1)\n",
    "    indices = cleanData[((spendings == 0) & (cleanData['CryoSleep'] == False) & (cleanData['Age'].isna() == True))].index\n",
    "    randomVals = np.random.choice([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], size = len(cleanData[((spendings == 0) & (cleanData['CryoSleep'] == False) & (cleanData['Age'].isna() == True))]), replace = True)\n",
    "    cleanData.loc[indices, 'Age'] = randomVals\n",
    "    cleanData['Age'] = randomFill(cleanData['Age'])\n",
    "    cleanData['RoomService'] = randomFill(cleanData['RoomService'])\n",
    "    cleanData['FoodCourt'] = randomFill(cleanData['FoodCourt'])\n",
    "    cleanData['ShoppingMall'] = randomFill(cleanData['ShoppingMall'])\n",
    "    cleanData['Spa'] = randomFill(cleanData['Spa'])\n",
    "    cleanData['VRDeck'] = randomFill(cleanData['VRDeck'])\n",
    "    cleanData.loc[cleanData['Age'] < 13, 'RoomService':'VRDeck'] = 0\n",
    "\n",
    "    #Final cleaning steps\n",
    "    cleanData.drop(columns = ['Name', 'Cabin'] , inplace = True)\n",
    "    cleanData['TotalSpendings'] = cleanData['RoomService'] + cleanData['FoodCourt'] + cleanData['ShoppingMall'] + cleanData['Spa'] + cleanData['VRDeck']\n",
    "    \n",
    "    return cleanData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00a57ae",
   "metadata": {},
   "source": [
    "Crazy that so much of our time spent on the other notebook and so much of our code there can be compressed to just this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf71a03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
